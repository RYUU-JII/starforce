"""
í™•ë¥  ì¡°ì‘ íƒì§€ë¥¼ ìœ„í•œ í†µê³„ ë¶„ì„ ëª¨ë“ˆ

ë¶„ì„ ë°©ë²•:
1. ë¶„ì‚° ê²€ì • (Variance Test): ì‹¤ì œ ë¶„ì‚°ì´ ì´ë¡ ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ì¡°ì‘ ì˜ì‹¬
2. Mean Reversion ë¶„ì„: í¸ì°¨ í›„ ë³µê·€ ì†ë„ê°€ ë¹„ì •ìƒì ì´ë©´ ì¡°ì‘ ì˜ì‹¬
3. ìê¸°ìƒê´€ ë¶„ì„ (Autocorrelation): ì—°ì† ì‹œê°„ëŒ€ ê²°ê³¼ê°€ ìƒê´€ë˜ë©´ ì¡°ì‘ ì˜ì‹¬
"""
import json
import math
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Optional
from collections import defaultdict
import statistics


@dataclass
class VarianceTestResult:
    """ë¶„ì‚° ê²€ì • ê²°ê³¼"""
    star_level: int
    event_type: str
    starcatch: bool
    
    sample_count: int               # ë¶„ì„í•œ ì‹œê°„ëŒ€ ìˆ˜
    total_trials: int               # ì´ ì‹œë„ íšŸìˆ˜
    
    expected_variance: float        # ì´ë¡ ì  ë¶„ì‚° (ë² ë¥´ëˆ„ì´)
    actual_variance: float          # ì‹¤ì œ ê´€ì¸¡ ë¶„ì‚°
    variance_ratio: float           # actual / expected
    
    # í•´ì„
    is_suspicious: bool             # ì¡°ì‘ ì˜ì‹¬ ì—¬ë¶€
    suspicion_reason: str           # ì˜ì‹¬ ì´ìœ 
    confidence_level: float         # ì‹ ë¢° ìˆ˜ì¤€ (0-1)


@dataclass
class MeanReversionResult:
    """Mean Reversion ë¶„ì„ ê²°ê³¼"""
    star_level: int
    event_type: str
    starcatch: bool
    
    sample_count: int
    
    # Reversion ì†ë„ (í¸ì°¨ í›„ ë³µê·€ê¹Œì§€ í‰ê·  ì‹œê°„)
    avg_reversion_speed: float      # ì‹œê°„ ë‹¨ìœ„
    expected_reversion: float       # ê¸°ëŒ€ ë³µê·€ ì‹œê°„ (ìì—°ì ì¸ ê²½ìš°)
    
    # í¸ì°¨-ë³µê·€ ìƒê´€ê³„ìˆ˜
    deviation_correction_corr: float  # í° í¸ì°¨ í›„ ë°˜ëŒ€ ë°©í–¥ ë³´ì •ì´ ê°•í•˜ë©´ ìŒìˆ˜
    
    is_suspicious: bool
    suspicion_reason: str


@dataclass 
class AnalysisSummary:
    """ì „ì²´ ë¶„ì„ ìš”ì•½"""
    session_name: str
    analyzed_at: str
    
    total_star_levels_analyzed: int
    suspicious_count: int
    
    variance_results: list[dict]
    mean_reversion_results: list[dict]
    
    overall_suspicion_score: float   # 0-100, ë†’ì„ìˆ˜ë¡ ì¡°ì‘ ì˜ì‹¬
    interpretation: str              # í•´ì„ ë¬¸êµ¬


class ManipulationDetector:
    """í™•ë¥  ì¡°ì‘ íƒì§€ê¸°"""
    
    # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ (ì‹œê°„ëŒ€ ìˆ˜)
    MIN_SAMPLES = 10
    # ì‹œê°„ë‹¹ ìµœì†Œ ì‹œë„ íšŸìˆ˜
    MIN_TRIALS_PER_HOUR = 50
    
    def __init__(self, session_dir: Path):
        self.session_dir = session_dir
        self.deltas_file = session_dir / "hourly_deltas.jsonl"
    
    def load_deltas(self) -> list[dict]:
        """Delta ë°ì´í„° ë¡œë“œ"""
        if not self.deltas_file.exists():
            return []
        
        deltas = []
        with open(self.deltas_file, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():
                    deltas.append(json.loads(line))
        return deltas
    
    def analyze(self) -> AnalysisSummary:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        deltas = self.load_deltas()
        
        if not deltas:
            return AnalysisSummary(
                session_name=self.session_dir.name,
                analyzed_at="N/A",
                total_star_levels_analyzed=0,
                suspicious_count=0,
                variance_results=[],
                mean_reversion_results=[],
                overall_suspicion_score=0.0,
                interpretation="ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì†Œ 10ì‹œê°„ ì´ìƒ ìˆ˜ì§‘ í›„ ë¶„ì„í•˜ì„¸ìš”."
            )
        
        # ê·¸ë£¹í™”: (star_level, event_type, starcatch) -> list of deltas
        grouped = self._group_deltas(deltas)
        
        variance_results = []
        reversion_results = []
        
        for key, group in grouped.items():
            if len(group) < self.MIN_SAMPLES:
                continue
            
            star, event, catch = key
            
            # ë¶„ì‚° ê²€ì •
            var_result = self._variance_test(star, event, catch, group)
            if var_result:
                variance_results.append(var_result)
            
            # Mean Reversion ë¶„ì„
            rev_result = self._mean_reversion_test(star, event, catch, group)
            if rev_result:
                reversion_results.append(rev_result)
        
        # ì „ì²´ ì˜ì‹¬ ì ìˆ˜ ê³„ì‚°
        suspicious_count = sum(1 for r in variance_results if r.is_suspicious)
        suspicious_count += sum(1 for r in reversion_results if r.is_suspicious)
        
        total_tests = len(variance_results) + len(reversion_results)
        suspicion_score = (suspicious_count / max(total_tests, 1)) * 100
        
        interpretation = self._interpret_score(suspicion_score, variance_results, reversion_results)
        
        from datetime import datetime
        return AnalysisSummary(
            session_name=self.session_dir.name,
            analyzed_at=datetime.now().isoformat(),
            total_star_levels_analyzed=len(grouped),
            suspicious_count=suspicious_count,
            variance_results=[asdict(r) for r in variance_results],
            mean_reversion_results=[asdict(r) for r in reversion_results],
            overall_suspicion_score=round(suspicion_score, 2),
            interpretation=interpretation
        )
    
    def _group_deltas(self, deltas: list) -> dict:
        """Deltaë¥¼ í‚¤ë³„ë¡œ ê·¸ë£¹í™”"""
        grouped = defaultdict(list)
        for d in deltas:
            key = (d["star_level"], d["event_type"], d["starcatch"])
            grouped[key].append(d)
        return grouped
    
    def _variance_test(self, star: int, event: str, catch: bool, 
                        deltas: list) -> Optional[VarianceTestResult]:
        """
        ë¶„ì‚° ê²€ì •: Binomial ë¶„í¬ì˜ ì´ë¡ ì  ë¶„ì‚°ê³¼ ì‹¤ì œ ë¶„ì‚° ë¹„êµ
        
        ì´ë¡ ì  ë¶„ì‚°: p * (1-p) / n (ê° ì‹œê°„ëŒ€ë³„)
        ì‹¤ì œ ë¶„ì‚°: ê´€ì¸¡ëœ ì„±ê³µë¥ ì˜ ë¶„ì‚°
        
        variance_ratio < 0.5 â†’ ë„ˆë¬´ ì¼ì •í•¨ (ì¡°ì‘ ì˜ì‹¬)
        variance_ratio > 2.0 â†’ ë„ˆë¬´ ë¶ˆê·œì¹™ (ë‹¤ë¥¸ ë¬¸ì œ)
        """
        # ì¶©ë¶„í•œ ì‹œë„ íšŸìˆ˜ê°€ ìˆëŠ” ì‹œê°„ëŒ€ë§Œ í•„í„°
        valid_deltas = [d for d in deltas if d["total_count"] >= self.MIN_TRIALS_PER_HOUR]
        
        if len(valid_deltas) < self.MIN_SAMPLES:
            return None
        
        # ê° ì‹œê°„ëŒ€ë³„ ì„±ê³µë¥  ê³„ì‚°
        success_rates = [d["actual_success_rate"] for d in valid_deltas]
        expected_rate = valid_deltas[0]["expected_success_rate"]
        
        # ì‹¤ì œ ë¶„ì‚°
        if len(success_rates) < 2:
            return None
        actual_variance = statistics.variance(success_rates)
        
        # ì´ë¡ ì  ë¶„ì‚° (í‰ê·  ì‹œë„ íšŸìˆ˜ ê¸°ì¤€)
        avg_n = statistics.mean([d["total_count"] for d in valid_deltas])
        expected_variance = (expected_rate * (1 - expected_rate)) / avg_n
        
        if expected_variance == 0:
            return None
        
        variance_ratio = actual_variance / expected_variance
        
        # íŒì •
        is_suspicious = False
        reason = ""
        confidence = 0.0
        
        if variance_ratio < 0.3:
            is_suspicious = True
            reason = f"ë¶„ì‚°ì´ ì´ë¡ ê°’ì˜ {variance_ratio:.1%}ë¡œ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŒ (ê°•ë ¥í•œ ì¡°ì‘ ì˜ì‹¬)"
            confidence = 0.9
        elif variance_ratio < 0.5:
            is_suspicious = True
            reason = f"ë¶„ì‚°ì´ ì´ë¡ ê°’ì˜ {variance_ratio:.1%}ë¡œ ë‚®ìŒ (ì¡°ì‘ ê°€ëŠ¥ì„±)"
            confidence = 0.7
        elif variance_ratio < 0.7:
            reason = f"ë¶„ì‚°ì´ ì´ë¡ ê°’ì˜ {variance_ratio:.1%}ë¡œ ë‹¤ì†Œ ë‚®ìŒ (ì£¼ì˜ ê´€ì°° í•„ìš”)"
            confidence = 0.4
        else:
            reason = f"ë¶„ì‚°ì´ ì´ë¡ ê°’ì˜ {variance_ratio:.1%}ë¡œ ì •ìƒ ë²”ìœ„"
            confidence = 0.1
        
        return VarianceTestResult(
            star_level=star,
            event_type=event,
            starcatch=catch,
            sample_count=len(valid_deltas),
            total_trials=sum(d["total_count"] for d in valid_deltas),
            expected_variance=expected_variance,
            actual_variance=actual_variance,
            variance_ratio=variance_ratio,
            is_suspicious=is_suspicious,
            suspicion_reason=reason,
            confidence_level=confidence
        )
    
    def _mean_reversion_test(self, star: int, event: str, catch: bool,
                              deltas: list) -> Optional[MeanReversionResult]:
        """
        Mean Reversion ë¶„ì„: í¸ì°¨ ë°œìƒ í›„ ë³µê·€ íŒ¨í„´ ë¶„ì„
        
        ìì—°ì ì¸ ê²½ìš°: í¸ì°¨ì™€ ë‹¤ìŒ ì‹œê°„ëŒ€ ê²°ê³¼ëŠ” ë¬´ìƒê´€ (ë…ë¦½)
        ì¡°ì‘ëœ ê²½ìš°: í° ì–‘ì˜ í¸ì°¨ í›„ ìŒì˜ í¸ì°¨ê°€ ë”°ë¼ì˜´ (ë³´ì •)
        
        deviation[t]ì™€ deviation[t+1]ì˜ ìƒê´€ê³„ìˆ˜ê°€ ê°•í•˜ê²Œ ìŒìˆ˜ë©´ ì¡°ì‘ ì˜ì‹¬
        """
        valid_deltas = [d for d in deltas if d["total_count"] >= self.MIN_TRIALS_PER_HOUR]
        
        if len(valid_deltas) < self.MIN_SAMPLES:
            return None
        
        expected_rate = valid_deltas[0]["expected_success_rate"]
        
        # í¸ì°¨ ì‹œê³„ì—´ ê³„ì‚°
        deviations = [d["actual_success_rate"] - expected_rate for d in valid_deltas]
        
        if len(deviations) < 3:
            return None
        
        # Lag-1 ìê¸°ìƒê´€ ê³„ì‚° (deviation[t]ì™€ deviation[t+1]ì˜ ìƒê´€)
        n = len(deviations)
        mean_dev = sum(deviations) / n
        
        numerator = sum((deviations[i] - mean_dev) * (deviations[i+1] - mean_dev) 
                        for i in range(n-1))
        denominator = sum((d - mean_dev) ** 2 for d in deviations)
        
        if denominator == 0:
            return None
        
        autocorr = numerator / denominator
        
        # ë³µê·€ ì†ë„ ê³„ì‚° (í° í¸ì°¨ í›„ ëª‡ ì‹œê°„ë§Œì— ì •ìƒí™”ë˜ëŠ”ì§€)
        # ê°„ì´ ê³„ì‚°: í¸ì°¨ ì ˆëŒ€ê°’ì´ ì„ê³„ì¹˜ ë„˜ì€ í›„ ë‹¤ì‹œ ë‚´ë ¤ì˜¤ê¸°ê¹Œì§€
        threshold = 0.05  # 5% í¸ì°¨
        reversion_times = []
        
        i = 0
        while i < len(deviations) - 1:
            if abs(deviations[i]) > threshold:
                # í¸ì°¨ ë°œìƒ, ë³µê·€ê¹Œì§€ ì‹œê°„ ì¸¡ì •
                j = i + 1
                while j < len(deviations) and abs(deviations[j]) > threshold * 0.5:
                    j += 1
                reversion_times.append(j - i)
                i = j
            else:
                i += 1
        
        avg_reversion = sum(reversion_times) / max(len(reversion_times), 1) if reversion_times else 0
        
        # ìì—°ì  ë³µê·€ ì‹œê°„ ì¶”ì • (ëŒ€ìˆ˜ì˜ ë²•ì¹™ ê¸°ì¤€)
        # ê°„ì´ ì¶”ì •: ë¶„ì‚°ì´ ì ˆë°˜ìœ¼ë¡œ ì¤„ë ¤ë©´ ì‹œí–‰ ìˆ˜ê°€ 4ë°° í•„ìš”
        avg_n = statistics.mean([d["total_count"] for d in valid_deltas])
        # ëŒ€ëµì ìœ¼ë¡œ 3-5ì‹œê°„ì´ ìì—°ì  ë³µê·€ ì‹œê°„ìœ¼ë¡œ ì¶”ì •
        expected_reversion = max(3.0, 10.0 * threshold / (expected_rate * (1 - expected_rate) / avg_n) ** 0.5)
        expected_reversion = min(expected_reversion, 10.0)  # ìµœëŒ€ 10ì‹œê°„
        
        # íŒì •
        is_suspicious = False
        reason = ""
        
        if autocorr < -0.5:
            is_suspicious = True
            reason = f"ê°•í•œ ìŒì˜ ìê¸°ìƒê´€({autocorr:.3f}): í¸ì°¨ í›„ ì¦‰ì‹œ ë°˜ëŒ€ ë°©í–¥ ë³´ì • ë°œìƒ (ê°•ë ¥í•œ ì¡°ì‘ ì˜ì‹¬)"
        elif autocorr < -0.3:
            is_suspicious = True
            reason = f"ìŒì˜ ìê¸°ìƒê´€({autocorr:.3f}): í¸ì°¨ì™€ ë‹¤ìŒ ì‹œê°„ ê²°ê³¼ê°€ ë°˜ëŒ€ ê²½í–¥ (ì¡°ì‘ ê°€ëŠ¥ì„±)"
        elif avg_reversion > 0 and avg_reversion < expected_reversion * 0.3:
            is_suspicious = True
            reason = f"ë¹„ì •ìƒì ìœ¼ë¡œ ë¹ ë¥¸ ë³µê·€({avg_reversion:.1f}ì‹œê°„ vs ì˜ˆìƒ {expected_reversion:.1f}ì‹œê°„)"
        else:
            reason = f"ìê¸°ìƒê´€({autocorr:.3f})ì´ ì •ìƒ ë²”ìœ„, ë³µê·€ ì†ë„ ì •ìƒ"
        
        return MeanReversionResult(
            star_level=star,
            event_type=event,
            starcatch=catch,
            sample_count=len(valid_deltas),
            avg_reversion_speed=avg_reversion,
            expected_reversion=expected_reversion,
            deviation_correction_corr=autocorr,
            is_suspicious=is_suspicious,
            suspicion_reason=reason
        )
    
    def _interpret_score(self, score: float, 
                          var_results: list, rev_results: list) -> str:
        """ì „ì²´ ì ìˆ˜ í•´ì„"""
        if score >= 70:
            return ("ğŸš¨ ë†’ì€ ì¡°ì‘ ì˜ì‹¬: ë‹¤ìˆ˜ì˜ ì„±/ì´ë²¤íŠ¸ ì¡°í•©ì—ì„œ ë¹„ì •ìƒì  íŒ¨í„´ ë°œê²¬. "
                    "í™•ë¥ ì´ ì¸ìœ„ì ìœ¼ë¡œ ì œì–´ë˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
        elif score >= 40:
            return ("âš ï¸ ì¤‘ê°„ ìˆ˜ì¤€ ì˜ì‹¬: ì¼ë¶€ ì¡°í•©ì—ì„œ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ë°œê²¬. "
                    "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ í›„ ì¬ë¶„ì„ ê¶Œì¥.")
        elif score >= 20:
            return ("ğŸ” ê²½ë¯¸í•œ ì´ìƒ: ëª‡ëª‡ ì¡°í•©ì—ì„œ ì•½ê°„ì˜ ì´ìƒ ë°œê²¬. "
                    "ìì—°ì  ë³€ë™ ë²”ìœ„ì¼ ìˆ˜ ìˆìœ¼ë‚˜ ëª¨ë‹ˆí„°ë§ ì§€ì† í•„ìš”.")
        else:
            return ("âœ… ì •ìƒ ë²”ìœ„: í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°ì—ì„œ ì¡°ì‘ ì§•í›„ ë¯¸ë°œê²¬. "
                    "í™•ë¥ ì´ ìì—°ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
    
    def save_report(self, summary: AnalysisSummary, output_path: Optional[Path] = None):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if output_path is None:
            output_path = self.session_dir / "analysis_report.json"
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(asdict(summary), f, ensure_ascii=False, indent=2)
        
        print(f"ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")
        return output_path


def run_analysis(session_dir: Path) -> AnalysisSummary:
    """ë¶„ì„ ì‹¤í–‰ í—¬í¼"""
    detector = ManipulationDetector(session_dir)
    summary = detector.analyze()
    detector.save_report(summary)
    return summary
